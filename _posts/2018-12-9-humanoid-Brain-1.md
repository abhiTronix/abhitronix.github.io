---
layout: post
title: "Design a Humanoid Brain-1"
subtitle: 'Part-1: What Artificial Intelligence really Is?'
author: "abhiTronix"
header-img: "img/brain-bg-1.jpg"
header-mask: 0.2
tags:
  - Deep Learning
  - Artificial Intelligence
  - Machine Learning
  
---

Update: 9 December 2018

---

Today, I'm going to discuss *"what really an Artifical Intelligence is?"*, thereby debunking some popular Artifical Intelligence myths and nailing down the truth. So let's get to it!

# Debunking the myths:

![](/img/in-post/manav/brain-1.jpg)

Back in 2017, after finishing my graduation, I decided to pursue my dream of getting into currently emerging technology "Artifical Intelligence". But like most of us, I have no idea where to start, what to refer to and what not to. So I decided to gather all resources I can find related to Artifical Intelligence like ebooks, video lectures, tutorials, blogs *etc.* and started to bind everything together so that everything can make sense to me. But, after being in research now for a while, I concluded Artifical Intelligence isn't just what we all think it is, let's debunk some harsh Artifical Intelligence myths and dug some real truth. Back when **SOPHIA THE ROBOT** first switched on, the world couldn’t get enough. It had a cheery personality, it joked with late-night hosts, it had facial expressions that echoed our own. Here it was, finally — a robot plucked straight out of science fiction, the closest thing to true artificial intelligence that we had ever seen. There’s no doubt that Sophia is an impressive piece of engineering. Hanson Robotics and SingularityNET equipped Sophia with sophisticated neural networks that give Sophia the ability to learn from people and to detect and mirror emotional responses, which makes it seem like the robot has a personality. But in reality, it didn’t take much to convince people of Sophia’s apparent humanity.

<iframe width="871" height="490" src="https://www.youtube.com/embed/ZQrKFAAlxO4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

As Sophia became more popular and people started to take a closer look, *cracks emerged*. It became harder to believe that Sophia was the all-encompassing artificial intelligence that we all wanted it to be. Over time, articles that might have once oohed and ahhed about *Sophia’s conversational skills became more focused on the fact that they were partially scripted in advance*. Hanson said that *" he finds it unfortunate when people think Sophia is capable of more or less than she really is, but also said that he doesn’t mind the benefits of the added hype."*  Hype which, again, has been bolstered by the two companies’ repeated publicity stunts. Highly-publicized projects like Sophia convince us that true AI — human-like and perhaps even conscious — is right around the corner. But in reality, we’re not even close. Take a closer look at the video below ;)

<iframe width="871" height="490" src="https://www.youtube.com/embed/7fnCQC7bLs0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

> “People think AI is a smart robot that can do things a very smart person would — a robot that knows everything and can answer any question” 

Among the ever-distant goalposts for *human-level artificial intelligence (HLAI)* are the ability to communicate effectively — *chatbots and machine learning-based language processors struggle to infer meaning or to understand nuance*, and the ability to continue learning over time. Currently, the AI systems with which we interact, including those being developed for self-driving cars, do all their learning before they are deployed and then stop forever. In machine learning, which includes deep learning and neural networks, an algorithm is presented with boatloads of training data — examples of whatever it is that the algorithm is learning to do, labeled by people — until it can complete the task on its own. For facial recognition software, this means feeding thousands of photos or videos of faces into the system until it can reliably detect a face from an unlabeled sample.

> "Artificial intelligence is now such a big catch-all term that practically any computer program that automatically does something is referred to as AI."

If you train an algorithm to multiply two numbers, it will just look up or copy the correct answer from a table. But it can’t generalize a better understanding of mathematical operations from its training. After learning that five multiply two ten seven, you might be able to figure out that six divided by two equals three. But if you ask your algorithm to divide two numbers after teaching it to multiply, it won’t be able to. The artificial intelligence, as it were, was trained to multiply only, not to understand what it means by multiple. Also, If you want it to divide, you’ll need to train it all over again — a process that notoriously wipes out whatever the AI system had previously learned. 


> "Yet, all the same, these machine learning systems are often touted as the cutting edge of artificial intelligence. In truth, they’re actually quite dumb."

Take, for example, an **image captioning algorithm**. Everyone was very impressed by the ability of the system, and soon it was found that 90 percent of these captions were actually found in the training data. So they were not actually produced by the machine; the machine just copied what it did see that the human annotators provided for a similar image so it seemed to have a lot of interesting complexity. It’s not some machine intelligence that you’re communicating with. It can be a useful system on its own, but it’s not AI. It took a while for people to realize the problems with the algorithm. At first, they were nothing but impressed.

---

# My Final Verdict: 
The problem is when our present-day systems, which are so limited, are marketed and hyped up to the point that the public believes we have technology that we have no goddamn clue how to build.

> “I am frequently entertained to see the way my research takes on exaggerated proportions as it progresses through the media, But there are also websites that pick up those primary stories and report on the technology without a solid understanding of how it works. The whole thing is a bit like a game of ‘telephone’ — the technical details of the project get lost and the system begins to seem self-willed and almost magical. At some point, I almost don’t recognize my own research anymore.” - said Nancy Fulda, a computer scientist.

The hype that comes from these sorts of algorithms helps the researcher sell their work and secure grants. Press people and journalists use it to draw audiences to their platforms. But the public suffers — this vicious cycle leaves everyone else unaware as to what AI can really do.

---

*Hey there, Hope you enjoy reading this article. If so, Share it with your family & friends! So Stay Tuned and Stay Creative ;)*